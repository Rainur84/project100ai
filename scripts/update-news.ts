import Parser from 'rss-parser';
import { writeFileSync } from 'fs';
import path from 'path';

type NewsItem = {
  title: string;
  link: string;
  pubDate: string;
  source: string;
};

const parser = new Parser();

const feeds = [
  { url: 'https://openai.com/blog/rss.xml', source: 'OpenAI News' },
  { url: 'https://blog.google/rss/', source: 'The Keyword' }
];

async function fetchNews(): Promise<NewsItem[]> {
  const allNews: NewsItem[] = [];

  for (const feed of feeds) {
    try {
      const parsed = await parser.parseURL(feed.url);
      parsed.items.slice(0, 10).forEach(item => {
        if (item.title && item.link && item.pubDate) {
          allNews.push({
            title: item.title,
            link: item.link,
            pubDate: item.pubDate,
            source: feed.source
          });
        }
      });
    } catch (err) {
      console.error(`Error fetching feed ${feed.url}:`, err);
    }
  }

  return allNews.sort((a, b) => new Date(b.pubDate).getTime() - new Date(a.pubDate).getTime()).slice(0, 10);
}

async function saveNewsToFile(news: NewsItem[]) {
  const filePath = path.join('src', 'data', 'aiNews.ts');
  const content = `// Auto-generated by update-news.ts
export const aiNews = ${JSON.stringify(news, null, 2)};
`;
  writeFileSync(filePath, content, 'utf8');
  console.log(`✅ Updated ${filePath} with ${news.length} items.`);
}

fetchNews()
  .then(saveNewsToFile)
  .catch(err => {
    console.error('❌ Failed to update AI news:', err);
    process.exit(1);
  });